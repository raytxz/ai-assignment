{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Deep Learning Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into deep learning modelling, we will first need to have a quick familiarisation with a deep learning framework. We recommend __[Keras](https://keras.io)__, which is built on top of Tensorflow, but alternatively, you can consider __[PyTorch](https://pytorch.org)__. Resources are abundant online on how to use them, but here are some official guides to get you started:\n",
    "- PyTorch has a [60 Minute Blitz Guide](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)\n",
    "- Tensorflow has an [Intro to Keras guide](https://www.tensorflow.org/guide/keras)\n",
    "\n",
    "A few words on the difference between Keras and PyTorch - Keras is a high level wrapper on top of Google's Tensorflow, the most popular deep learning framework out there. Being more low level, Tensorflow faces many issues and troubles, which are addressed by the abstractions of Keras, making it a great way to start. Facebook's PyTorch on the other hand is a newcomer which has received massive interest in recent years, and is playing catch up to Tensorflow/Keras.\n",
    "\n",
    "If you are more interested in how deep learning software has evolved since the days of Caffe and Theano as well as more in depth into what is happening in the software behind the scenes, we also recommend a [full lecture from Stanford](https://www.youtube.com/watch?v=6SlgtELqOWc) on this topic, although this is extra knowledge that isn't fully critical to this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on the tutorials you go through, you should be ready to build a 2 (or more) layer Multi-Level Perceptron (MLP) with deep learning. With the dataset you have prepared your machine learning model in the previous section, run your data through a MLP model with `Dense` (`Linear`) layers instead. Do some slight model adjustments, and discuss what kind of adjustments lead to improvements in score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import pickle\n",
    "import requests\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data transformations/preprocessing\n",
    "\n",
    "Most neural networks expect the images of a fixed size. Therefore, you will need to write some prepocessing code. At the basic level, you will need to normalise the data. Use the appropriate data generator/loader methods to encapsulate your data for training purposes. Do the same for both the train and test (and val, if exist) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"data/raw/\")\n",
    "file_to_open = data_folder / \"cifar-10-python.tar.gz\"\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def getRawDictionary(fileName):\n",
    "    batch = data_folder / \"cifar-10-batches-py\" / fileName\n",
    "    data = unpickle(batch)\n",
    "    return data\n",
    "\n",
    "train_imgs = []\n",
    "train_labels = []\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    data_batch = getRawDictionary(\"data_batch_\" + str(i))\n",
    "    if i == 1:\n",
    "        train_imgs = data_batch[b'data']\n",
    "        train_labels = np.asarray(data_batch[b'labels'])\n",
    "    else:\n",
    "        train_imgs = np.concatenate((train_imgs, data_batch[b'data']), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, np.asarray(data_batch[b'labels'])), axis=0)\n",
    "#         train_imgs = numpy.append(train_imgs, data_batch[b'data'], axis=0)\n",
    "#         train_labels = numpy.append(train_labels, np.asarray(data_batch[b'labels']), axis=0)\n",
    "    \n",
    "test_batch = getRawDictionary(\"test_batch\")\n",
    "test_imgs = test_batch[b'data']\n",
    "test_labels= np.asarray(test_batch[b'labels'])\n",
    "\n",
    "label_dict = getRawDictionary(\"batches.meta\")\n",
    "label_names = label_dict[b'label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.shape)\n",
    "print(test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_encoded = to_categorical(train_labels)\n",
    "test_labels_encoded = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = train_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "\n",
    "def toGrayScale(imgs):\n",
    "    R = imgs[:,0:1024]\n",
    "    G = imgs[:,1024:2048]\n",
    "    B = imgs[:,2048:]\n",
    "\n",
    "    imgs_grey = (R + G + B)/3\n",
    "    return imgs_grey\n",
    "\n",
    "train_imgs_grey = toGrayScale(train_imgs)\n",
    "test_imgs_grey = toGrayScale(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def drawGrayScale(img, img_index):\n",
    "    plt.imshow(img[17,:].reshape(32,32), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "drawGrayScale(train_imgs_grey, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Build multi-layer perceptron neural network models with Keras \n",
    "\n",
    "The Keras Python library for deep learning focuses on the creation of models as a sequence of layers.\n",
    "\n",
    "In here, you will discover the simple components that you can use to create neural networks and simple deep learning models using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = train_imgs_grey.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu',input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 9s 243us/step - loss: 2.0415 - acc: 0.2570 - val_loss: 1.9333 - val_acc: 0.3042\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 5s 156us/step - loss: 1.8990 - acc: 0.3186 - val_loss: 1.8804 - val_acc: 0.3227\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 5s 155us/step - loss: 1.8419 - acc: 0.3413 - val_loss: 1.8486 - val_acc: 0.3411\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 5s 152us/step - loss: 1.8029 - acc: 0.3566 - val_loss: 1.8182 - val_acc: 0.3467\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 5s 152us/step - loss: 1.7711 - acc: 0.3685 - val_loss: 1.7815 - val_acc: 0.3655\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 5s 152us/step - loss: 1.7457 - acc: 0.3762 - val_loss: 1.8033 - val_acc: 0.3579\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 5s 155us/step - loss: 1.7249 - acc: 0.3848 - val_loss: 1.7741 - val_acc: 0.3681\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 6s 158us/step - loss: 1.7059 - acc: 0.3914 - val_loss: 1.7777 - val_acc: 0.3667\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 5s 157us/step - loss: 1.6929 - acc: 0.3982 - val_loss: 1.7495 - val_acc: 0.3795\n",
      "Epoch 10/40\n",
      "35000/35000 [==============================] - 5s 153us/step - loss: 1.6671 - acc: 0.4053 - val_loss: 1.7402 - val_acc: 0.3789\n",
      "Epoch 11/40\n",
      "35000/35000 [==============================] - 5s 153us/step - loss: 1.6560 - acc: 0.4072 - val_loss: 1.7430 - val_acc: 0.3795\n",
      "Epoch 12/40\n",
      "35000/35000 [==============================] - 5s 154us/step - loss: 1.6420 - acc: 0.4127 - val_loss: 1.7552 - val_acc: 0.3803\n",
      "Epoch 13/40\n",
      "35000/35000 [==============================] - 5s 154us/step - loss: 1.6280 - acc: 0.4167 - val_loss: 1.7250 - val_acc: 0.3865\n",
      "Epoch 14/40\n",
      "35000/35000 [==============================] - 6s 160us/step - loss: 1.6128 - acc: 0.4276 - val_loss: 1.7306 - val_acc: 0.3897\n",
      "Epoch 15/40\n",
      "35000/35000 [==============================] - 5s 156us/step - loss: 1.5997 - acc: 0.4302 - val_loss: 1.7210 - val_acc: 0.3878\n",
      "Epoch 16/40\n",
      "35000/35000 [==============================] - 5s 153us/step - loss: 1.5903 - acc: 0.4334 - val_loss: 1.7263 - val_acc: 0.3903\n",
      "Epoch 17/40\n",
      "35000/35000 [==============================] - 5s 154us/step - loss: 1.5778 - acc: 0.4370 - val_loss: 1.7250 - val_acc: 0.3864\n",
      "Epoch 18/40\n",
      "35000/35000 [==============================] - 5s 154us/step - loss: 1.5639 - acc: 0.4433 - val_loss: 1.7352 - val_acc: 0.3907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25680796ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_imgs_grey, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 42us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7128542533874511, 0.4002]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_imgs_grey, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the MLP network in CIFAR-10\n",
    "\n",
    "The main objective is to train the MLP network to achieve a balance between the ability to respond correctly to the input patterns that are used for training and the ability to provide good response to the input that is similar. Use the stochastic gradient descent optimiser with an appropriate learning rate between 1e-2 and 1e-3. Report your evaluation loss and accuracy, and you can also consider doing things like early stopping to prevent overfitting and achieve the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.001000\n",
      "\n",
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 5s 144us/step - loss: 2.2733 - acc: 0.1600 - val_loss: 2.2420 - val_acc: 0.1927\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 2.2137 - acc: 0.2140 - val_loss: 2.1878 - val_acc: 0.2249\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 2.1564 - acc: 0.2394 - val_loss: 2.1355 - val_acc: 0.2359\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 5s 131us/step - loss: 2.1118 - acc: 0.2485 - val_loss: 2.1030 - val_acc: 0.2457\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 2.0815 - acc: 0.2567 - val_loss: 2.0762 - val_acc: 0.2510\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 2.0586 - acc: 0.2639 - val_loss: 2.0598 - val_acc: 0.2615\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 2.0408 - acc: 0.2711 - val_loss: 2.0460 - val_acc: 0.2663\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 5s 137us/step - loss: 2.0268 - acc: 0.2764 - val_loss: 2.0338 - val_acc: 0.2669\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 2.0144 - acc: 0.2810 - val_loss: 2.0253 - val_acc: 0.2766\n",
      "Epoch 10/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 2.0042 - acc: 0.2863 - val_loss: 2.0177 - val_acc: 0.2788\n",
      "Epoch 11/40\n",
      "35000/35000 [==============================] - 5s 132us/step - loss: 1.9946 - acc: 0.2895 - val_loss: 2.0073 - val_acc: 0.2875\n",
      "Epoch 12/40\n",
      "35000/35000 [==============================] - 5s 130us/step - loss: 1.9855 - acc: 0.2950 - val_loss: 1.9980 - val_acc: 0.2915\n",
      "Epoch 13/40\n",
      "35000/35000 [==============================] - 5s 132us/step - loss: 1.9774 - acc: 0.2997 - val_loss: 1.9912 - val_acc: 0.2955\n",
      "Epoch 14/40\n",
      "35000/35000 [==============================] - 5s 131us/step - loss: 1.9692 - acc: 0.3032 - val_loss: 1.9816 - val_acc: 0.2918\n",
      "Epoch 15/40\n",
      "35000/35000 [==============================] - 5s 131us/step - loss: 1.9616 - acc: 0.3047 - val_loss: 1.9746 - val_acc: 0.2949\n",
      "Epoch 16/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.9533 - acc: 0.3096 - val_loss: 1.9708 - val_acc: 0.2911\n",
      "Epoch 17/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.9456 - acc: 0.3113 - val_loss: 1.9621 - val_acc: 0.3003\n",
      "Epoch 18/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.9385 - acc: 0.3153 - val_loss: 1.9565 - val_acc: 0.3009\n",
      "Epoch 19/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.9312 - acc: 0.3164 - val_loss: 1.9485 - val_acc: 0.3069\n",
      "Epoch 20/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.9239 - acc: 0.3200 - val_loss: 1.9413 - val_acc: 0.3087\n",
      "Epoch 21/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 1.9159 - acc: 0.3226 - val_loss: 1.9341 - val_acc: 0.3105\n",
      "Epoch 22/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.9090 - acc: 0.3254 - val_loss: 1.9271 - val_acc: 0.3149\n",
      "Epoch 23/40\n",
      "35000/35000 [==============================] - 5s 140us/step - loss: 1.9015 - acc: 0.3283 - val_loss: 1.9228 - val_acc: 0.3178\n",
      "Epoch 24/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.8944 - acc: 0.3308 - val_loss: 1.9145 - val_acc: 0.3156\n",
      "Epoch 25/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.8872 - acc: 0.3349 - val_loss: 1.9091 - val_acc: 0.3201\n",
      "Epoch 26/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 1.8795 - acc: 0.3390 - val_loss: 1.9037 - val_acc: 0.3229\n",
      "Epoch 27/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.8727 - acc: 0.3400 - val_loss: 1.8961 - val_acc: 0.3245\n",
      "Epoch 28/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 1.8657 - acc: 0.3422 - val_loss: 1.8907 - val_acc: 0.3251\n",
      "Epoch 29/40\n",
      "35000/35000 [==============================] - 4s 124us/step - loss: 1.8595 - acc: 0.3454 - val_loss: 1.8851 - val_acc: 0.3297\n",
      "Epoch 30/40\n",
      "35000/35000 [==============================] - 5s 132us/step - loss: 1.8535 - acc: 0.3475 - val_loss: 1.8806 - val_acc: 0.3331\n",
      "Epoch 31/40\n",
      "35000/35000 [==============================] - 4s 128us/step - loss: 1.8468 - acc: 0.3501 - val_loss: 1.8758 - val_acc: 0.3342\n",
      "Epoch 32/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 1.8412 - acc: 0.3509 - val_loss: 1.8693 - val_acc: 0.3377\n",
      "Epoch 33/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.8345 - acc: 0.3545 - val_loss: 1.8700 - val_acc: 0.3342\n",
      "Epoch 34/40\n",
      "35000/35000 [==============================] - 4s 124us/step - loss: 1.8294 - acc: 0.3540 - val_loss: 1.8616 - val_acc: 0.3390\n",
      "Epoch 35/40\n",
      "35000/35000 [==============================] - 5s 132us/step - loss: 1.8239 - acc: 0.3559 - val_loss: 1.8554 - val_acc: 0.3403\n",
      "Epoch 36/40\n",
      "35000/35000 [==============================] - 4s 128us/step - loss: 1.8190 - acc: 0.3596 - val_loss: 1.8534 - val_acc: 0.3431\n",
      "Epoch 37/40\n",
      "35000/35000 [==============================] - 5s 129us/step - loss: 1.8138 - acc: 0.3601 - val_loss: 1.8457 - val_acc: 0.3474\n",
      "Epoch 38/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.8082 - acc: 0.3616 - val_loss: 1.8451 - val_acc: 0.3473\n",
      "Epoch 39/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.8041 - acc: 0.3643 - val_loss: 1.8381 - val_acc: 0.3476\n",
      "Epoch 40/40\n",
      "35000/35000 [==============================] - 4s 124us/step - loss: 1.7992 - acc: 0.3646 - val_loss: 1.8367 - val_acc: 0.3497\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.005000\n",
      "\n",
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 5s 153us/step - loss: 2.1916 - acc: 0.1997 - val_loss: 2.1014 - val_acc: 0.2448\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 5s 130us/step - loss: 2.0537 - acc: 0.2625 - val_loss: 2.0253 - val_acc: 0.2730\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.9931 - acc: 0.2887 - val_loss: 1.9838 - val_acc: 0.2950\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.9489 - acc: 0.3068 - val_loss: 1.9526 - val_acc: 0.3029\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 4s 128us/step - loss: 1.9119 - acc: 0.3227 - val_loss: 1.9172 - val_acc: 0.3203\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.8785 - acc: 0.3339 - val_loss: 1.8902 - val_acc: 0.3303\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.8511 - acc: 0.3428 - val_loss: 1.8754 - val_acc: 0.3401\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.8251 - acc: 0.3548 - val_loss: 1.8590 - val_acc: 0.3402\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.8057 - acc: 0.3610 - val_loss: 1.8451 - val_acc: 0.3504\n",
      "Epoch 10/40\n",
      "35000/35000 [==============================] - 4s 127us/step - loss: 1.7846 - acc: 0.3702 - val_loss: 1.8257 - val_acc: 0.3555\n",
      "Epoch 11/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.7676 - acc: 0.3777 - val_loss: 1.7936 - val_acc: 0.3669\n",
      "Epoch 12/40\n",
      "35000/35000 [==============================] - 5s 136us/step - loss: 1.7517 - acc: 0.3795 - val_loss: 1.7764 - val_acc: 0.3721\n",
      "Epoch 13/40\n",
      "35000/35000 [==============================] - 5s 131us/step - loss: 1.7371 - acc: 0.3848 - val_loss: 1.7734 - val_acc: 0.3709\n",
      "Epoch 14/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.7237 - acc: 0.3906 - val_loss: 1.7895 - val_acc: 0.3648\n",
      "Epoch 15/40\n",
      "35000/35000 [==============================] - 4s 127us/step - loss: 1.7097 - acc: 0.3936 - val_loss: 1.7486 - val_acc: 0.3785\n",
      "Epoch 16/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.6985 - acc: 0.3986 - val_loss: 1.7536 - val_acc: 0.3819\n",
      "Epoch 17/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.6874 - acc: 0.4011 - val_loss: 1.7684 - val_acc: 0.3661\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000/35000 [==============================] - 5s 132us/step - loss: 1.6759 - acc: 0.4045 - val_loss: 1.7220 - val_acc: 0.3928\n",
      "Epoch 19/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.6643 - acc: 0.4111 - val_loss: 1.7331 - val_acc: 0.3831\n",
      "Epoch 20/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.6537 - acc: 0.4142 - val_loss: 1.7130 - val_acc: 0.3923\n",
      "Epoch 21/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.6433 - acc: 0.4184 - val_loss: 1.7446 - val_acc: 0.3818\n",
      "Epoch 22/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.6348 - acc: 0.4177 - val_loss: 1.7443 - val_acc: 0.3833\n",
      "Epoch 23/40\n",
      "35000/35000 [==============================] - 5s 130us/step - loss: 1.6248 - acc: 0.4278 - val_loss: 1.7165 - val_acc: 0.3961\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 5s 147us/step - loss: 2.1656 - acc: 0.2026 - val_loss: 2.0801 - val_acc: 0.2361\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 2.0265 - acc: 0.2743 - val_loss: 1.9917 - val_acc: 0.2875\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.9630 - acc: 0.3021 - val_loss: 1.9647 - val_acc: 0.2869\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.9078 - acc: 0.3238 - val_loss: 1.9090 - val_acc: 0.3236\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.8621 - acc: 0.3398 - val_loss: 1.8552 - val_acc: 0.3437\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.8267 - acc: 0.3535 - val_loss: 1.8318 - val_acc: 0.3504\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 4s 128us/step - loss: 1.7965 - acc: 0.3639 - val_loss: 1.8207 - val_acc: 0.3559\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.7734 - acc: 0.3701 - val_loss: 1.8258 - val_acc: 0.3492\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.7545 - acc: 0.3785 - val_loss: 1.7813 - val_acc: 0.3639\n",
      "Epoch 10/40\n",
      "35000/35000 [==============================] - 5s 140us/step - loss: 1.7353 - acc: 0.3851 - val_loss: 1.7598 - val_acc: 0.3726\n",
      "Epoch 11/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.7187 - acc: 0.3934 - val_loss: 1.7666 - val_acc: 0.3766\n",
      "Epoch 12/40\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 1.7016 - acc: 0.3996 - val_loss: 1.7760 - val_acc: 0.3689\n",
      "Epoch 13/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.6871 - acc: 0.4038 - val_loss: 1.7304 - val_acc: 0.3866\n",
      "Epoch 14/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.6712 - acc: 0.4109 - val_loss: 1.7310 - val_acc: 0.3912\n",
      "Epoch 15/40\n",
      "35000/35000 [==============================] - 5s 132us/step - loss: 1.6597 - acc: 0.4111 - val_loss: 1.7079 - val_acc: 0.3967\n",
      "Epoch 16/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.6444 - acc: 0.4187 - val_loss: 1.7204 - val_acc: 0.3902\n",
      "Epoch 17/40\n",
      "35000/35000 [==============================] - 5s 130us/step - loss: 1.6313 - acc: 0.4230 - val_loss: 1.7618 - val_acc: 0.3781\n",
      "Epoch 18/40\n",
      "35000/35000 [==============================] - 4s 127us/step - loss: 1.6204 - acc: 0.4283 - val_loss: 1.6993 - val_acc: 0.4019\n",
      "Epoch 19/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.6076 - acc: 0.4321 - val_loss: 1.6842 - val_acc: 0.4039\n",
      "Epoch 20/40\n",
      "35000/35000 [==============================] - 5s 130us/step - loss: 1.5969 - acc: 0.4377 - val_loss: 1.7474 - val_acc: 0.3881\n",
      "Epoch 21/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.5838 - acc: 0.4409 - val_loss: 1.7140 - val_acc: 0.3872\n",
      "Epoch 22/40\n",
      "35000/35000 [==============================] - 4s 127us/step - loss: 1.5734 - acc: 0.4439 - val_loss: 1.6788 - val_acc: 0.4011\n",
      "Epoch 23/40\n",
      "35000/35000 [==============================] - 4s 126us/step - loss: 1.5618 - acc: 0.4478 - val_loss: 1.6655 - val_acc: 0.4069\n",
      "Epoch 24/40\n",
      "35000/35000 [==============================] - 4s 127us/step - loss: 1.5541 - acc: 0.4497 - val_loss: 1.7271 - val_acc: 0.3885\n",
      "Epoch 25/40\n",
      "35000/35000 [==============================] - 5s 137us/step - loss: 1.5431 - acc: 0.4549 - val_loss: 1.7040 - val_acc: 0.3988\n",
      "Epoch 26/40\n",
      "35000/35000 [==============================] - 5s 131us/step - loss: 1.5346 - acc: 0.4563 - val_loss: 1.6839 - val_acc: 0.4077\n",
      "10000/10000 [==============================] - 0s 42us/step\n"
     ]
    }
   ],
   "source": [
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.001,0.005,0.01]\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "score_list = []\n",
    "acc_list = []\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu',input_shape=(n_cols,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(train_imgs_grey, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor])\n",
    "    \n",
    "    # Evaluate the final model\n",
    "    score, acc = model.evaluate(test_imgs_grey, test_labels_encoded, batch_size=32)\n",
    "    \n",
    "    score_list.append(score)\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score_list, 'r', acc_list, 'b')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Score/Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate of 0.001: Score: 1.8159462215423583 - Accuracy: 0.3537\n",
      "Learning Rate of 0.005: Score: 1.701442984008789 - Accuracy: 0.3959\n",
      "Learning Rate of 0.01: Score: 1.6682677238464356 - Accuracy: 0.412\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Rate of 0.001: Score: \" + str(score_list[0]) + \" - Accuracy: \" + str(acc_list[0]))\n",
    "print(\"Learning Rate of 0.005: Score: \" + str(score_list[1]) + \" - Accuracy: \" + str(acc_list[1]))\n",
    "print(\"Learning Rate of 0.01: Score: \" + str(score_list[2]) + \" - Accuracy: \" + str(acc_list[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate of 0.001 is too small. The model have not converge yet by the 40th epoch. Learning rate of 0.005 and 0.01 appears to be able converge and triggered the early stop. However the use of adam optimiser was even better, it allowed for a faster convergent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
