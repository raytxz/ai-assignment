{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Multi Level Perceptron from Scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we attempted to train a simple 2 layer MLP on Keras. Keras, being a high level abstracted framework, hides the details behind the model and simplifies the process. We will now try to build our own 2 layer MLP, purely out of NumPy, which will unveil the hidden components of neural network training. Similar to past from-scratch attempts, we will start by creating a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a class `MLPTwoLayers`\n",
    "\n",
    "- One of the starting points to take care of while building your network is to initialize your weight matrix correctly. Consider appropriate sizes for your input, hidden and output layers - your __init__ method should take in the params `input_size`, `hidden_size`, `output_size`. Then, using these variables, initialise the weights for the hidden layers `w1`, `w2`, `b1`, and `b2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# from src.mlp import MLPTwoLayers as MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = MLP(3072, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a `forward ` method, which takes in a set of features\n",
    "- Create the `forward` method to calculate the predicted class probabilities of an image. This is known as a forward pass.  You should wrap the hidden layer with a sigmoid function (or others if you prefer), and the output layer with a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import your data preparation methods here, ensure your data is randomized\n",
    "# preds = mlp.forward(X[0])\n",
    "# preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a `loss` method, which takes in the predicted probability and actual label\n",
    "- Compute the loss function: This is a function of the actual label y and predicted label y. It captures how far off our predictions are from the actual target. The objective is to minimize this loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss = mlp.loss(preds, y[0])\n",
    "# train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a `backward` method, which takes in the loss\n",
    "- Using the backpropogation algorithm, execute the backward pass and adjust the weights and bias accordingly\n",
    "- You can use a default learning rate of 1e-3 for this exercise. If you would like do otherwise, you can try to implement it as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.backward(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial attempt at training\n",
    "# test_loss = 0\n",
    "# for i in range(3000, 3500):\n",
    "#     test_loss += mlp.loss(mlp.forward(X[i]), y[i])\n",
    "# print(test_loss / 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3000):\n",
    "#     if i % 100:\n",
    "#         print('Item {}'.format(i))\n",
    "#     mlp.backward(mlp.loss(mlp.forward(X[i]), y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, re-test your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = 0\n",
    "# for i in range(3000, 3500):\n",
    "#     test_loss += mlp.loss(mlp.forward(X[i]), y[i])\n",
    "# print(test_loss / 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you see that your test loss has decreased after training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Convolutional Neural Network (CNN)\n",
    "Please attempt this section only after you have completed the rest!\n",
    "\n",
    "In the previous part, you implemented a multilayer perceptron network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as you move to bigger models. Ideally, you want to build networks using a more modular design so that you can implement different layer types in isolation and then snap them together into models with different architectures.\n",
    "\n",
    "In this part of exercise, you will implement a close to state-of-the-art deep learning model for CIFAR-10 with the Keras Deep Learning library. In addition to implementing convolutional networks of various depth, you will need to explore different update rules for optimization, and introduce **Dropout** as a regularizer, **Batch Normalization** and **Data Augmentation** as a tool to more efficiently optimize deep networks.\n",
    "\n",
    "We saw models performing >98% accuracy on `CIFAR-10`, while most state-of-the-art models cross the 97% boundary. In general, models beyond **95%** are fairly decent.\n",
    "\n",
    "## Reading resources\n",
    "\n",
    "[Dropout](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer) is a regularization technique for overfitting in neural networks by preventing complex co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks.\n",
    "\n",
    "[Batch Normalization](https://pdfs.semanticscholar.org/c1ba/ed41e4bc9401b1b2ec8ef55ba45543f7a1a3.pdf) is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance.\n",
    "\n",
    "[Data Augmentation](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced) means increasing the number of data points. In terms of images, it may mean that increasing the number of images in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Enhancing the performance of you existing model in part 2 with convolutional neural networks\n",
    "- The implementation of model should be done by using Keras (or PyTorch)\n",
    "- Train your designed model \n",
    "- Improve performance with algorithm tuning: Dropout, Batch normalization, Data augmentation and other optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import pickle\n",
    "import requests\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"data/raw/\")\n",
    "file_to_open = data_folder / \"cifar-10-python.tar.gz\"\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def getRawDictionary(fileName):\n",
    "    batch = data_folder / \"cifar-10-batches-py\" / fileName\n",
    "    data = unpickle(batch)\n",
    "    return data\n",
    "\n",
    "train_imgs = []\n",
    "train_labels = []\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    data_batch = getRawDictionary(\"data_batch_\" + str(i))\n",
    "    if i == 1:\n",
    "        train_imgs = data_batch[b'data']\n",
    "        train_labels = np.asarray(data_batch[b'labels'])\n",
    "    else:\n",
    "        train_imgs = np.concatenate((train_imgs, data_batch[b'data']), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, np.asarray(data_batch[b'labels'])), axis=0)\n",
    "#         train_imgs = numpy.append(train_imgs, data_batch[b'data'], axis=0)\n",
    "#         train_labels = numpy.append(train_labels, np.asarray(data_batch[b'labels']), axis=0)\n",
    "    \n",
    "test_batch = getRawDictionary(\"test_batch\")\n",
    "test_imgs = test_batch[b'data']\n",
    "test_labels= np.asarray(test_batch[b'labels'])\n",
    "\n",
    "label_dict = getRawDictionary(\"batches.meta\")\n",
    "label_names = label_dict[b'label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_encoded = to_categorical(train_labels)\n",
    "test_labels_encoded = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = train_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0\n",
    "\n",
    "def toGrayScale(imgs):\n",
    "    R = imgs[:,0:1024]\n",
    "    G = imgs[:,1024:2048]\n",
    "    B = imgs[:,2048:]\n",
    "\n",
    "    imgs_grey = (R + G + B)/3\n",
    "    return imgs_grey\n",
    "\n",
    "train_imgs_grey = toGrayScale(train_imgs)\n",
    "test_imgs_grey = toGrayScale(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = train_imgs_grey.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu',input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 11s 302us/step - loss: 2.0470 - acc: 0.2533 - val_loss: 1.9319 - val_acc: 0.3115\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.8976 - acc: 0.3191 - val_loss: 1.8916 - val_acc: 0.3240\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.8308 - acc: 0.3469 - val_loss: 1.8312 - val_acc: 0.3515\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.7966 - acc: 0.3586 - val_loss: 1.8133 - val_acc: 0.3595\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 5s 133us/step - loss: 1.7647 - acc: 0.3718 - val_loss: 1.8019 - val_acc: 0.3620\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 5s 142us/step - loss: 1.7368 - acc: 0.3792 - val_loss: 1.7675 - val_acc: 0.3693\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 5s 147us/step - loss: 1.7173 - acc: 0.3862 - val_loss: 1.7796 - val_acc: 0.3687\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 5s 144us/step - loss: 1.7006 - acc: 0.3942 - val_loss: 1.7625 - val_acc: 0.3777\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 5s 141us/step - loss: 1.6822 - acc: 0.4020 - val_loss: 1.7446 - val_acc: 0.3796\n",
      "Epoch 10/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.6648 - acc: 0.4064 - val_loss: 1.7611 - val_acc: 0.3747\n",
      "Epoch 11/40\n",
      "35000/35000 [==============================] - 5s 134us/step - loss: 1.6512 - acc: 0.4133 - val_loss: 1.7263 - val_acc: 0.3863\n",
      "Epoch 12/40\n",
      "35000/35000 [==============================] - 5s 135us/step - loss: 1.6372 - acc: 0.4184 - val_loss: 1.7444 - val_acc: 0.3767\n",
      "Epoch 13/40\n",
      "35000/35000 [==============================] - 5s 137us/step - loss: 1.6255 - acc: 0.4203 - val_loss: 1.7044 - val_acc: 0.3989\n",
      "Epoch 14/40\n",
      "35000/35000 [==============================] - 5s 141us/step - loss: 1.6133 - acc: 0.4245 - val_loss: 1.7231 - val_acc: 0.3912\n",
      "Epoch 15/40\n",
      "35000/35000 [==============================] - 5s 141us/step - loss: 1.6048 - acc: 0.4289 - val_loss: 1.7058 - val_acc: 0.3958\n",
      "Epoch 16/40\n",
      "35000/35000 [==============================] - 5s 137us/step - loss: 1.5884 - acc: 0.4341 - val_loss: 1.7321 - val_acc: 0.3840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a9786cc18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_imgs_grey, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7296526000976562, 0.3879]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_imgs_grey, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_reshape(df):\n",
    "    n_images = len(df.index)\n",
    "    img_array = (df.iloc[:, 0:1024]).values\n",
    "    img_tensor = img_array.reshape(n_images, 32,32,1)\n",
    "    return img_tensor\n",
    "\n",
    "train_imgs_grey_reshape = tensor_reshape(pd.DataFrame(train_imgs_grey))\n",
    "test_imgs_grey_reshape = tensor_reshape(pd.DataFrame(test_imgs_grey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 14s 387us/step - loss: 1.7216 - acc: 0.3931 - val_loss: 1.5230 - val_acc: 0.4641\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 11s 311us/step - loss: 1.3815 - acc: 0.5246 - val_loss: 1.3397 - val_acc: 0.5417\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 11s 301us/step - loss: 1.1659 - acc: 0.6034 - val_loss: 1.2970 - val_acc: 0.5568\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 11s 305us/step - loss: 1.0409 - acc: 0.6472 - val_loss: 1.2473 - val_acc: 0.5837\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 11s 303us/step - loss: 0.9422 - acc: 0.6834 - val_loss: 1.3176 - val_acc: 0.5654\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 11s 315us/step - loss: 0.8382 - acc: 0.7175 - val_loss: 1.2645 - val_acc: 0.5887\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 11s 306us/step - loss: 0.7479 - acc: 0.7490 - val_loss: 1.3821 - val_acc: 0.5589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bf38ea940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(32,32,1)))\n",
    "cnn_model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_imgs_grey_reshape, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 101us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3840419342041015, 0.5593]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(test_imgs_grey_reshape, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 15s 431us/step - loss: 2.1219 - acc: 0.4443 - val_loss: 1.4824 - val_acc: 0.4968\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 14s 412us/step - loss: 1.1273 - acc: 0.6139 - val_loss: 3.3154 - val_acc: 0.2675\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 15s 415us/step - loss: 0.9552 - acc: 0.6737 - val_loss: 1.3592 - val_acc: 0.5363\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 14s 411us/step - loss: 0.8011 - acc: 0.7267 - val_loss: 1.4211 - val_acc: 0.5405\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 15s 418us/step - loss: 0.6469 - acc: 0.7799 - val_loss: 2.0907 - val_acc: 0.4410\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 15s 419us/step - loss: 0.4978 - acc: 0.8307 - val_loss: 1.9456 - val_acc: 0.4695\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 15s 431us/step - loss: 0.3740 - acc: 0.8727 - val_loss: 4.2515 - val_acc: 0.3758\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 15s 421us/step - loss: 0.2851 - acc: 0.9029 - val_loss: 1.8902 - val_acc: 0.5181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bfa13ae80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor_norm = EarlyStopping(patience=5)\n",
    "\n",
    "cnn_model_norm = Sequential()\n",
    "cnn_model_norm.add(Conv2D(64, kernel_size=3, input_shape=(32,32,1)))\n",
    "cnn_model_norm.add(BatchNormalization())\n",
    "cnn_model_norm.add(Activation(\"relu\"))\n",
    "cnn_model_norm.add(Conv2D(32, kernel_size=3))\n",
    "cnn_model_norm.add(BatchNormalization())\n",
    "cnn_model_norm.add(Activation(\"relu\"))\n",
    "cnn_model_norm.add(Flatten())\n",
    "cnn_model_norm.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn_model_norm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model_norm.fit(train_imgs_grey_reshape, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 127us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9523200534820557, 0.5113]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_norm.evaluate(test_imgs_grey_reshape, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 26s 732us/step - loss: 1.6690 - acc: 0.4150 - val_loss: 1.4250 - val_acc: 0.5029\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 15s 431us/step - loss: 1.3122 - acc: 0.5448 - val_loss: 1.2886 - val_acc: 0.5550\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 15s 427us/step - loss: 1.1497 - acc: 0.6066 - val_loss: 1.2475 - val_acc: 0.5683\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 15s 442us/step - loss: 1.0435 - acc: 0.6458 - val_loss: 1.1950 - val_acc: 0.5881\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 15s 441us/step - loss: 0.9577 - acc: 0.6715 - val_loss: 1.2004 - val_acc: 0.5963\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 15s 432us/step - loss: 0.8938 - acc: 0.6955 - val_loss: 1.2213 - val_acc: 0.5894\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 15s 440us/step - loss: 0.8328 - acc: 0.7150 - val_loss: 1.2333 - val_acc: 0.5985\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 15s 439us/step - loss: 0.7723 - acc: 0.7372 - val_loss: 1.2537 - val_acc: 0.5946\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 16s 449us/step - loss: 0.7247 - acc: 0.7506 - val_loss: 1.3389 - val_acc: 0.5851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25c15b5a7f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor_dropout = EarlyStopping(patience=5)\n",
    "\n",
    "cnn_model_dropout = Sequential()\n",
    "cnn_model_dropout.add(Conv2D(64, kernel_size=3, input_shape=(32,32,1)))\n",
    "cnn_model_dropout.add(Dropout(0.2))\n",
    "cnn_model_dropout.add(Activation(\"relu\"))\n",
    "cnn_model_dropout.add(Conv2D(32, kernel_size=3))\n",
    "cnn_model_dropout.add(Dropout(0.2))\n",
    "cnn_model_dropout.add(Activation(\"relu\"))\n",
    "cnn_model_dropout.add(Flatten())\n",
    "cnn_model_dropout.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn_model_dropout.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model_dropout.fit(train_imgs_grey_reshape, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor_dropout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 195us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3496148273468018, 0.5766]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_dropout.evaluate(test_imgs_grey_reshape, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with Batch Normalisation and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/40\n",
      "35000/35000 [==============================] - 27s 767us/step - loss: 1.8412 - acc: 0.4279 - val_loss: 3.1201 - val_acc: 0.2375\n",
      "Epoch 2/40\n",
      "35000/35000 [==============================] - 20s 557us/step - loss: 1.2020 - acc: 0.5860 - val_loss: 1.7794 - val_acc: 0.4144\n",
      "Epoch 3/40\n",
      "35000/35000 [==============================] - 20s 562us/step - loss: 1.0388 - acc: 0.6466 - val_loss: 1.5884 - val_acc: 0.4460\n",
      "Epoch 4/40\n",
      "35000/35000 [==============================] - 20s 559us/step - loss: 0.9295 - acc: 0.6828 - val_loss: 1.5224 - val_acc: 0.4941\n",
      "Epoch 5/40\n",
      "35000/35000 [==============================] - 20s 579us/step - loss: 0.8290 - acc: 0.7137 - val_loss: 1.4301 - val_acc: 0.5060\n",
      "Epoch 6/40\n",
      "35000/35000 [==============================] - 20s 561us/step - loss: 0.7358 - acc: 0.7463 - val_loss: 1.8043 - val_acc: 0.4253\n",
      "Epoch 7/40\n",
      "35000/35000 [==============================] - 20s 576us/step - loss: 0.6588 - acc: 0.7706 - val_loss: 1.3506 - val_acc: 0.5565\n",
      "Epoch 8/40\n",
      "35000/35000 [==============================] - 20s 574us/step - loss: 0.5848 - acc: 0.7972 - val_loss: 1.4627 - val_acc: 0.5473\n",
      "Epoch 9/40\n",
      "35000/35000 [==============================] - 21s 590us/step - loss: 0.5202 - acc: 0.8197 - val_loss: 1.3669 - val_acc: 0.5727\n",
      "Epoch 10/40\n",
      "35000/35000 [==============================] - 21s 593us/step - loss: 0.4744 - acc: 0.8333 - val_loss: 1.3312 - val_acc: 0.5903\n",
      "Epoch 11/40\n",
      "35000/35000 [==============================] - 20s 583us/step - loss: 0.4283 - acc: 0.8483 - val_loss: 1.4063 - val_acc: 0.5796\n",
      "Epoch 12/40\n",
      "35000/35000 [==============================] - 19s 557us/step - loss: 0.3935 - acc: 0.8615 - val_loss: 1.5125 - val_acc: 0.5659\n",
      "Epoch 13/40\n",
      "35000/35000 [==============================] - 19s 552us/step - loss: 0.3691 - acc: 0.8681 - val_loss: 1.6076 - val_acc: 0.5347\n",
      "Epoch 14/40\n",
      "35000/35000 [==============================] - 19s 557us/step - loss: 0.3398 - acc: 0.8806 - val_loss: 1.6802 - val_acc: 0.5461.8 - ETA: 3s -\n",
      "Epoch 15/40\n",
      "35000/35000 [==============================] - 20s 569us/step - loss: 0.3144 - acc: 0.8883 - val_loss: 1.8094 - val_acc: 0.5351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25c270e1eb8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor_combi = EarlyStopping(patience=5)\n",
    "\n",
    "cnn_model_combi = Sequential()\n",
    "cnn_model_combi.add(Conv2D(64, kernel_size=3, input_shape=(32,32,1)))\n",
    "cnn_model_combi.add(Dropout(0.2))\n",
    "cnn_model_combi.add(BatchNormalization())\n",
    "cnn_model_combi.add(Activation(\"relu\"))\n",
    "cnn_model_combi.add(Conv2D(32, kernel_size=3))\n",
    "cnn_model_combi.add(Dropout(0.2))\n",
    "cnn_model_combi.add(BatchNormalization())\n",
    "cnn_model_combi.add(Activation(\"relu\"))\n",
    "cnn_model_combi.add(Flatten())\n",
    "cnn_model_combi.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn_model_combi.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model_combi.fit(train_imgs_grey_reshape, train_labels_encoded, epochs=40, validation_split=0.3, callbacks=[early_stopping_monitor_combi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 204us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8176016143798828, 0.5277]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_combi.evaluate(test_imgs_grey_reshape, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref:\n",
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "<br>\n",
    "https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16\n",
    "<br>\n",
    "https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
